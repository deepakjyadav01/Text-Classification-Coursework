{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99b7ae69-743b-422f-9c44-7c168185c711",
   "metadata": {},
   "source": [
    "Import libraries and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2762a29a-c38c-452b-8a6b-7de90a23a03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b50833-87e6-49a6-a4da-e9cf975ef5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601e3ba5-146d-4718-b8d3-724bb91a76a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273df81b-a30a-48be-ba69-69317bf37fad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e5089165-ebc5-4226-ae86-e6f2f3d7fb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data from multiple folders\n",
    "def load_data_from_folders(folder_paths):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for folder_path in folder_paths:\n",
    "        category = os.path.basename(folder_path)  # Extract category name from folder path\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r', encoding='latin-1') as file:\n",
    "                text = file.read()\n",
    "                data.append(text)\n",
    "                labels.append(category)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "96b66881-ecbd-4081-8e59-f51fe2daeadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_paths = [\"bbc/tech\", \"bbc/sport\", \"bbc/politics\", \"bbc/entertainment\", \"bbc/business\"]\n",
    "data, labels = load_data_from_folders(folder_paths)\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(labels)\n",
    "df = pd.DataFrame({'text': data, 'category': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c778ed35-85cf-4ac2-81f3-13411a29aa37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ink helps drive democracy in Asia\\n\\nThe Kyrgy...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China net cafe culture crackdown\\n\\nChinese au...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Microsoft seeking spyware trojan\\n\\nMicrosoft ...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Digital guru floats sub-$100 PC\\n\\nNicholas Ne...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Technology gets the creative bug\\n\\nThe hi-tec...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text category\n",
       "0  Ink helps drive democracy in Asia\\n\\nThe Kyrgy...     tech\n",
       "1  China net cafe culture crackdown\\n\\nChinese au...     tech\n",
       "2  Microsoft seeking spyware trojan\\n\\nMicrosoft ...     tech\n",
       "3  Digital guru floats sub-$100 PC\\n\\nNicholas Ne...     tech\n",
       "4  Technology gets the creative bug\\n\\nThe hi-tec...     tech"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e036630-86a0-4307-af31-21ef93504844",
   "metadata": {},
   "source": [
    "Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c1080d3c-1806-4003-8a3a-525f9a28f7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text category\n",
      "0  ink help drive democraci asia kyrgyz republ sm...     tech\n",
      "1  china net cafe cultur crackdown chines author ...     tech\n",
      "2  microsoft seek spywar trojan microsoft investi...     tech\n",
      "3  digit guru float sub- 100 pc nichola negropont...     tech\n",
      "4  technolog get creativ bug hi-tech art world ti...     tech\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Step 2: Data Preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Removing Punctuation\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "    \n",
    "    # Removing Stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Join tokens back into a single string\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    return preprocessed_text\n",
    "\n",
    "# Apply preprocessing to the 'text' column of the DataFrame\n",
    "df['text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# Display the preprocessed text\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1f0fa217-1dc1-4185-badc-bb6da656c24f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Frequency Feature Matrix Shape: (2225, 21060)\n",
      "TF-IDF Feature Matrix Shape: (2225, 21060)\n",
      "N-grams Feature Matrix Shape: (2225, 339763)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# Step 3: Feature Engineering\n",
    "\n",
    "# 1. Word Frequency Feature\n",
    "count_vectorizer = CountVectorizer()\n",
    "word_freq_features = count_vectorizer.fit_transform(df['text'])\n",
    "\n",
    "# 2. TF-IDF Feature\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(df['text'])\n",
    "\n",
    "# 3. N-grams Feature\n",
    "ngram_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "ngram_features = ngram_vectorizer.fit_transform(df['text'])\n",
    "\n",
    "#Compute Cosine Similarity between documents\n",
    "cos_sim_features = cosine_similarity(tfidf_features)\n",
    "\n",
    "# Display the updated feature matrix\n",
    "print(\"Word Frequency Feature Matrix Shape:\", word_freq_features.shape)\n",
    "print(\"TF-IDF Feature Matrix Shape:\", tfidf_features.shape)\n",
    "print(\"N-grams Feature Matrix Shape:\", ngram_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "87313806-29d8-44cb-b416-a1f9dcbde66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.02940013 0.01321327 ... 0.00906117 0.03338321 0.01651119]\n",
      " [0.02940013 1.         0.02737986 ... 0.01591812 0.03581663 0.00796929]\n",
      " [0.01321327 0.02737986 1.         ... 0.01262462 0.01649719 0.00827267]\n",
      " ...\n",
      " [0.00906117 0.01591812 0.01262462 ... 1.         0.10009538 0.01908958]\n",
      " [0.03338321 0.03581663 0.01649719 ... 0.10009538 1.         0.02502272]\n",
      " [0.01651119 0.00796929 0.00827267 ... 0.01908958 0.02502272 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(cos_sim_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "584cdf35-9381-4d01-923d-590dde2314ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Features Matrix Shape: (2225, 384108)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "# 1. Combine Features\n",
    "# Combine the extracted features into a single feature matrix\n",
    "# Use hstack() from scipy.sparse to horizontally stack the feature matrices\n",
    "combined_features = hstack([word_freq_features, tfidf_features, ngram_features, cos_sim_features])\n",
    "\n",
    "# Check the shape of the combined feature matrix\n",
    "print(\"Combined Features Matrix Shape:\", combined_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ce554297-704a-4eb4-9128-becacca819fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 10082)\t25.0\n",
      "  (0, 9252)\t1.0\n",
      "  (0, 6501)\t3.0\n",
      "  (0, 5870)\t2.0\n",
      "  (0, 2403)\t1.0\n",
      "  (0, 11096)\t4.0\n",
      "  (0, 15868)\t4.0\n",
      "  (0, 17432)\t1.0\n",
      "  (0, 12964)\t1.0\n",
      "  (0, 17921)\t1.0\n",
      "  (0, 7921)\t2.0\n",
      "  (0, 17640)\t2.0\n",
      "  (0, 19869)\t12.0\n",
      "  (0, 10237)\t2.0\n",
      "  (0, 19465)\t3.0\n",
      "  (0, 15529)\t3.0\n",
      "  (0, 5273)\t3.0\n",
      "  (0, 6782)\t15.0\n",
      "  (0, 14216)\t3.0\n",
      "  (0, 15012)\t1.0\n",
      "  (0, 13047)\t1.0\n",
      "  (0, 20208)\t1.0\n",
      "  (0, 13331)\t1.0\n",
      "  (0, 18658)\t2.0\n",
      "  (0, 4239)\t4.0\n",
      "  :\t:\n",
      "  (2224, 384083)\t0.03707898166235673\n",
      "  (2224, 384084)\t0.0237400086033047\n",
      "  (2224, 384085)\t0.017983615579618806\n",
      "  (2224, 384086)\t0.022750852156378235\n",
      "  (2224, 384087)\t0.009127948773602065\n",
      "  (2224, 384088)\t0.02782863310988535\n",
      "  (2224, 384089)\t0.027153315759018946\n",
      "  (2224, 384090)\t0.03844869823162835\n",
      "  (2224, 384091)\t0.05445865444742223\n",
      "  (2224, 384092)\t0.011130000010751866\n",
      "  (2224, 384093)\t0.01022090111775944\n",
      "  (2224, 384094)\t0.016418050251233055\n",
      "  (2224, 384095)\t0.012402764882923798\n",
      "  (2224, 384096)\t0.014271460106339163\n",
      "  (2224, 384097)\t0.032760851071717945\n",
      "  (2224, 384098)\t0.022110114584740777\n",
      "  (2224, 384099)\t0.005334536281749187\n",
      "  (2224, 384100)\t0.019218780243107577\n",
      "  (2224, 384101)\t0.0331158699899881\n",
      "  (2224, 384102)\t0.01816781941390838\n",
      "  (2224, 384103)\t0.0062452794612448525\n",
      "  (2224, 384104)\t0.010807937805094552\n",
      "  (2224, 384105)\t0.01908958183435934\n",
      "  (2224, 384106)\t0.02502271947259558\n",
      "  (2224, 384107)\t0.9999999999999997\n"
     ]
    }
   ],
   "source": [
    "print(combined_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5e6b4cfd-61c1-4def-a24d-0d815a9b43a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features Matrix Shape: (2225, 3000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Perform feature selection using SelectKBest\n",
    "# Here, we'll select the top 2000 features\n",
    "k_best_selector = SelectKBest(score_func=chi2, k=3000)\n",
    "selected_features = k_best_selector.fit_transform(combined_features, y)\n",
    "\n",
    "# Check the shape of the selected feature matrix\n",
    "print(\"Selected Features Matrix Shape:\", selected_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2090fb56-af1c-4e79-9862-5d0084888f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624b5315-2ade-455f-806c-c846402299b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "858b454e-a6b7-42b4-901e-c529a87f12cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9483146067415731\n"
     ]
    }
   ],
   "source": [
    "X = selected_features  # Selected features matrix\n",
    "y = df['category']  # Labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Model Selection\n",
    "classifier = SVC()  # Example classifier, you can use any other classifier\n",
    "\n",
    "# 3. Model Training\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# 4. Model Evaluation\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1ce0ff24-0d29-4af1-b45d-e6c24fb54617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.97      0.91      0.94       102\n",
      "entertainment       1.00      0.92      0.96        76\n",
      "     politics       0.95      0.94      0.94        78\n",
      "        sport       0.97      0.98      0.98       104\n",
      "         tech       0.87      0.99      0.92        85\n",
      "\n",
      "     accuracy                           0.95       445\n",
      "    macro avg       0.95      0.95      0.95       445\n",
      " weighted avg       0.95      0.95      0.95       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9018406a-5f5d-4f0b-822e-80f942956cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.95786517 0.94662921 0.95786517 0.95505618 0.96348315]\n",
      "Mean Accuracy: 0.9561797752808989\n",
      "Standard Deviation of Accuracy: 0.005504471332097002\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.97      0.91      0.94       102\n",
      "entertainment       1.00      0.92      0.96        76\n",
      "     politics       0.95      0.94      0.94        78\n",
      "        sport       0.97      0.98      0.98       104\n",
      "         tech       0.87      0.99      0.92        85\n",
      "\n",
      "     accuracy                           0.95       445\n",
      "    macro avg       0.95      0.95      0.95       445\n",
      " weighted avg       0.95      0.95      0.95       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming you have already trained your classifier\n",
    "# Let's assume your classifier is named 'classifier'\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "k_folds = 5\n",
    "\n",
    "# Define the cross-validation strategy (k-fold)\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation and get accuracy scores for each fold\n",
    "cv_scores = cross_val_score(classifier, X_train, y_train, cv=kfold)\n",
    "\n",
    "# Print the accuracy scores for each fold\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "\n",
    "# Calculate and print the mean accuracy and standard deviation\n",
    "print(\"Mean Accuracy:\", np.mean(cv_scores))\n",
    "print(\"Standard Deviation of Accuracy:\", np.std(cv_scores))\n",
    "\n",
    "# Generate predictions on the test data using the trained classifier\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2706584-e09d-4a09-a95a-b407fa8360d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852d95a6-c6c9-4429-94ce-bd2ce26f4cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a2289e-3556-458c-928c-fd7cf2b1f6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
